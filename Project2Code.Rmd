---
title: "Project2"
author: "Landon Batts, Jose Singer-Freeman"
date: "2023-07-02"
output: github_document
params: 
      channel: ""
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, cache = TRUE)
#if currently blocked, unblock the channel parameter

if (bindingIsLocked("params", env = .GlobalEnv)==TRUE) {
      unlockBinding("params", env = .GlobalEnv)}

```

```{r load packages, include=FALSE}
library(tidyverse)
library(caret)
library(leaps)
library(doParallel)
library(dplyr)
library(corrplot)
library(knitr)
library(DescTools)
library(reshape2)
```
## 1.Introducton


In this project we work with the [online news popularity data set](https://archive.ics.uci.edu/dataset/332/online+news+popularity)  published by UC Irvine  The data set summarizes a heterogeneous set of features about articles published by Mashable in a period of two years.  

Our goal is to predict the number of "shares" (popularity) of articles in social networks.  This is done separately for 6 different types or "channels" of articles, namely, lifestyle, entertainment, business, social media, tech and world news.     

Our predictive models for shares consist of two linear regression models, a random forest model and a boosted tree model for each of the 6 channels. 


##  2.  Import Data


```{r import and wrangle data}
#Get data
raw_data<-read.csv("~/ST558/Project2/OnlineNewsPopularity.csv")

# Remove variables we won't use
newsData<-raw_data %>% select(-c(url,timedelta))

#Filter data from a single channel (just as test) using the parameter params$channel

#store business channel the global channel parameter 
params$channel<-"data_channel_is_bus"

# convert the parameter into a name and then select the rows  where the channel is 1
channelData<-newsData %>% filter(eval(as.name(params$channel))==1)



```


##  3. Basic Summary Statistics

The table below shows pairs of variables whose correlation, in absolute terms, is above 0.5.  For those that exceed 0.9, we will drop a member of each pair of variables from our models, namely,  kw_avg_min, n_non_stop_unique_tokens, and rate_negative_words.

### Summary Statistics

```{r correlation}
#Correlation
tempordata<-channelData[-c(12:17)] #remove channel variables
corMat<-cor(tempordata, use="pairwise.complete.obs")

# Find highest correlations.  First drop higher triangle to avoid duplicates and remove the diagonal. 
corMat[lower.tri(corMat,diag=TRUE)] <- NA  # drop upper triangle
corMat[corMat == 1] <- NA  #drop perfect correlations

corMat <- as.data.frame(as.table(corMat)) #form a  table with 3 columns: 2-variables and their correlation
corMat <- na.omit(corMat) #remove missing values

corMat<-subset(corMat, abs(Freq) > 0.5) #select correlation values above 0.5  
corMat <- corMat[order(-abs(corMat$Freq)),] #sort by highest to lowest correlation
knitr::kable(corMat, col.names=as.vector(c("Variable 1", "Variable 2", "Correlation")),  digits = 2)

#turn corr back into matrix in order to plot with corrplot
  corMat2 <- reshape2::acast(corMat, Var1~Var2, value.var="Freq") #melt the data
  corrplot(corMat2, is.corr=FALSE, tl.col="black", na.label=" ") #plot  correlations absolute value above 0.5

  #get correlation of shares with other variables
  
  share_cor <- sort(desc(cor(tempordata[ , colnames(tempordata) != "shares"],  
                tempordata$shares)))
  
tempordata<-channelData[-c(12:17)] #remove channel variables  
```


```{r weekday summary}

t<-channelData%>%select(shares,starts_with("weekday_is"))%>%
    mutate(day_of_week=factor(case_when(as.logical(weekday_is_monday)~"Monday",
                             as.logical(weekday_is_tuesday)~"Tuesday",
                             as.logical(weekday_is_wednesday)~"Wednesday",
                             as.logical(weekday_is_thursday)~"Thursday",
                             as.logical(weekday_is_friday)~"Friday",
                             as.logical(weekday_is_saturday)~"Saturday",
                             as.logical(weekday_is_sunday)~"Sunday"),ordered=TRUE,levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))%>%
  select(-starts_with("weekday_is"))%>%
  group_by(day_of_week)%>%
    dplyr::summarize("Average Shares"=mean(shares, na.rm=TRUE), "Number of Articles"=n())
t
```

### Plots
```{r plots and summaries}
#We can inspect the trend of the amount of shares as a function of the number of word in the content itself. If the points show an upward trend,then longer articles are shared more often. On the other hand, if there is a negative trend, then shorter articles are shared more.
g <- ggplot(channelData, aes(x=n_tokens_content,y=shares))
g + geom_point() + geom_smooth() +
  labs(title="Word Count vs Shares",x="Number of Words in Content", y="Amount of Shares")

#In order to get an idea of the number of shares we are dealing with, a 5 number summary can be created to get an idea of the distribution, along with standard deviation to get an idea of the spread
summarise(channelData,min=min(shares),
          Q1=quantile(shares,0.25),
          med=quantile(shares,0.5),
          mean=mean(shares),
          sd=sd(shares),
          Q3=quantile(shares,.75),
          max=max(shares)
          )

#To visualize this, a box plot can be created to visualize the spread and the 5 number summary 
g2 <- ggplot(channelData,aes(x=shares))
g2 + geom_boxplot() + xlim(0,5000) + 
  labs(title="Shares Boxplot",x="Amount of Shares")
```

##  4. Modeling

We first split the data for each channel into 70% for testing and 30% for training. 
```{r split data}
#use set.seed for reproducibility
set.seed(101)

trainIndex <-caret::createDataPartition(channelData$shares, p = 0.7, list = FALSE)

training <-channelData[trainIndex,]
testing <-channelData[-trainIndex,]

```

For all models we will use 10-fold cross-validation repeated 5 times for each type of model.  Using the caret package, we set up the "control" that provides for this cross-validation. 

```{r control}
#We will use repeated 10-fold cv for all predictive techniques 

controlObject<-trainControl(method = "repeatedcv", 
                        number = 10, 
                        repeats=5)
```

```{r remove zero variance}
#remove predictors with near zero variance (including indicators for other channels)

# check how much variance there is for all variables 
#nzv <- nearZeroVar(channelData, saveMetrics= TRUE)

#removed 8 variables with low variance

# Get variables with zero or near-zero variance and remove them from the dataframe
nzv <- nearZeroVar(channelData)
filteredChannelData <- channelData[, -nzv]

```



### Linear Models
Linear Models is a type of statistical analysis in which a formula is created and used to predict the relationship between variables. It assumes a straight, linear relationship between variables and attempts to find a line of best fit in order to relate them. Here, we will attempt to perform linear regression in which we try to predict shares using the all other variables as independent.
####  Linear Regression Model 1
Performed a simple linear regression with all variables except those with zero variance. Also, preprocessed the data by centering and scaling.
``` {r linear regression model 1}
set.seed(102)
lm1Fit <- train(shares~., data=filteredChannelData,
                method="lm",
                preProcess=c("center","scale"),
                trControl=controlObject)
lm1Fit
predictionlm1 <- predict(lm1Fit,newdata = testing)
# #Get RMSE value
lm1_RMSE<-postResample(predictionlm1, obs = testing$shares)["RMSE"][[1]]
lm1_RMSE
```

####  Linear Regression Model 2

Performed forward step-wise regression.  Excluded variable that was found to have zero variance.  Terrible results.

```{r linear regression model 2}
#Note: Need to remove one day of week and 

set.seed(102)

# clust <- parallel::makePSOCKcluster(5)
# doParallel::registerDoParallel(clust)
# 
# lm2fit <- train(
#   shares~.,
#   data = filteredChannelData,
#   trControl= controlObject,
#   method= "lmStepAIC",
#   direction = "backward",
#   trace = FALSE,
#   preProcess =c("center","scale"),
#   na.action = na.omit,
#   verbose = FALSE)
# 
# predictionLm2 <- predict(lm2fit,newdata = testing)
# #Get RMSE value
# lm2_RMSE<-postResample(predictionLm2, obs = testing$shares)["RMSE"][[1]]

```


###  Random Forest Model
The random forest model is an extension of the idea of bootstrap aggregation in which multiple trees are created from bootstrap samples and results are averaged. The difference is that only a random subset of the predictors for each sample/fit.
```{r rf model}
set.seed(102)
#randomforestFit <- train(shares~.,data=filteredChannelData,
               #method="rf",
               #trControl=controlObject,
               #tuneGrid=data.frame(mtry=1:10))
#rfFit$results
#rfFit$bestTune
#predictionrf <- predict(rfFit,newdata = testing)
#postResample(predictionrf, obs = filteredChannelData$shares)
```

###  Boosted Tree Model

```{r boost tree}

# formula using all variables other than those that have zero variance

# BTformula<-as.formula("shares~.")
# 
# set.seed(102)
# 
# tunegridBT<-expand.grid(n.trees=c(25, 50, 100, 150, 200), 
#                            interaction.depth=1:4, 
#                            shrinkage=0.1, 
#                            n.minobsinnode=10)
# 
# BTfit <- train(
#   form = BTformula,
#   data = filteredChannelData,
#   trControl= controlObject,
#   method="gbm",
#   tuneGrid=tunegridBT,
#   preProcess =c("center","scale"),
#   na.action = na.omit,
#   verbose = FALSE)
# 
# predictionBT <- predict(BTfit,newdata = testing)
# postResample(predictionBT, obs = filteredChannelData$shares)


```

## Model Comparisons

We calculate the RMSE for each model using the  testing data.  The  winning model will be the one  with lowest RMSE.

```{r model comparison}

```

